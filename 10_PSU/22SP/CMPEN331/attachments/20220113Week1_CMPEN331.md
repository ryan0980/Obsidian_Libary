## Chapter  1 

Computer  Abstractions  and Technology 

# Lecture 1 &2 

---

- Syllabus 

---

###### The  Computer  Revolution 

- Progress  in  computer  technology 

- Underpinned  by  Moore’s  Law 

- Makes  novel  applications  feasible 

- Computers  in  automobiles 

- Cell  phones 

- Human  genome  project 

- World  Wide  Web 

- Search  Engines 

- Computers  are  pervasive 

---

###### Classes  of  Computers 

- Desktop  computers 

- General  purpose,  variety  of  software 

- Subject  to  cost/performance  tradeoff 

- Server  computers 

- Network  based 

- High  capacity,  performance,  reliability 

- Range  from  small  servers  to  building  sized 

- Embedded  computers 

- Hidden  as  components  of  systems 

- Stringent  power/performance/cost  constraints 

---

###### What  You  Will  Learn 

- How  programs  are  translated  into  the  machine     language 

- And  how  the  hardware  executes  them 

- The  hardware/software  interface 

- What  determines  program  performance 

- And  how  it  can  be  improved 

- How  hardware  designers  improve  performance 

- What  is  parallel  processing 

---

###### Understanding  Performance 

- Algorithm 

- Determines  number  of  operations  executed 

- Programming  language,  compiler, 

architecture 

- Determine  number  of  machine  instructions     executed  per  operation 

- Processor  and  memory  system 

- Determine  how  fast  instructions  are  executed 

- I/O  system  (including  OS) 

- Determines  how  fast  I/O  operations  are  executed 

---

###### Below  Your  Program 

- Application  software 

- Written  in  high-­level  language  (HLL) 

- System  software 

- Compiler:  translates  HLL  code  to     machine  code 

- Operating  System: 

- Handling  input/output 

- Managing  memory  and  storage 

- Scheduling  tasks  &  sharing  resources 

- Hardware 

- Processor,  memory,  I/O  controllers 

---

###### Levels  of  Program  Code 

- High-­level  language 

- Level  of  abstraction  closer     to  problem  domain 

- Provides  for  productivity     and  portability 

- Assembly  language 

- Textual  representation  of     instructions 

- Hardware  representation 

- Binary  digits  (bits) 

- Encoded  instructions  and     data 

---

###### Components  of  a  Computer 

- Same  components  for     all  kinds  of  computer 

- Desktop,  server,     embedded 

- Input/output  includes 

- User-­interface  devices 

- Display,  keyboard,  mouse 

- Storage  devices 

- Hard  disk,  CD/DVD,  flash 

- Network  adapters 

- For  communicating  with     other  computers 

The BIG Picture 

---

###### Opening  the  Box 

---

###### Inside  the  Processor  (CPU) 

- Datapath:  performs  operations  on  data 

- Control:  sequences  datapath,  memory,  ... 

- Cache  memory 

- Small  fast  SRAM  memory  for  immediate  access  to     data 

---

###### Inside  the  Processor 

- AMD:  4  processor  cores 

---

###### A  Safe  Place  for  Data 

- Volatile  main  memory 

- Loses  instructions  and  data  when  power  off 

- Non-­volatile  secondary  memory 

- Magnetic  disk 

- Flash  memory 

- Optical  disk  (CDROM,  DVD) 

---

###### Networks 

- Communication  and  resource  sharing 

- Local  area  network  (LAN):  Ethernet 

- Within  a  building 

- Wide  area  network  (WAN:  the  Internet 

- Wireless  network:  WiFi,  Bluetooth 

---

###### Technology  Trends 

- Electronics 

 technology continues  to  evolve 

- Increased  capacity     and  performance 

- Reduced  cost 

 Ye a r Technology Relative  performance/cost 1951 Vacuum  tube 1 1965 Transistor 35 1975 Integrated  circuit  (IC) 900 1995 Very  large  scale  IC  (VLSI) 2,400,000 2005 Ultra  large  scale  IC 6,200,000,000 

 DRAM  capacity 

---

#### Response  Time  and  Throughput 

- Response  time 

- How  long  it  takes  to  do  a  task 

- Throughput 

- Total  work  done  per  unit  time 

- e.g.,  tasks/transactions/...  per  hour 

- How  are  response  time  and  throughput 

affected  by 

- Replacing  the  processor  with  a  faster  version? 

- Adding  more  processors? 

- We’ll  focus  on  response  time  for  now... 

---

###### Relative  Performance 

- Define  Performance  =  1/Execution  Time 

- “X  is _n_ time  faster  than  Y” 

= Y X = _n_ 

 X Y Execution time Execution time 

Performance Performance 

###### n Example:  time  taken  to  run  a  program 

 n 10s  on  A,  15s  on  B n Execution  TimeB /  Execution  TimeA =  15s  /  10s  =  1.5 n So  A  is  1.5  times  faster  than  B 

---

###### Measuring  Execution  Time 

- Elapsed  time 

- Total  response  time,  including  all  aspects 

- Processing,  I/O,  OS  overhead,  idle  time 

- Determines  system  performance 

- CPU  time 

- Time  spent  processing  a  given  job 

- Discounts  I/O  time,  other  jobs’  shares 

- Different  programs  are  affected  differently  by  CPU  and     system  performance 

---

###### CPU  Clocking 

- Operation  of  digital  hardware  governed  by  a 

constant-­rate  clock 

Clock  (cycles) 

Data  transfer and  computation 

Update  state 

 Clock  period 

 n Clock  period:  duration  of  a  clock  cycle n e.g.,  250ps  =  0.25ns  =  250× 10 –^12 s n Clock  frequency  (rate):  cycles  per  second n e.g.,  4.0GHz  =  4000MHz  =  4.0× 109 Hz 

---

###### CPU  Time 

- Performance  improved  by 

- Reducing  number  of  clock  cycles 

- Increasing  clock  rate 

- Hardware  designer  must  often  trade  off  clock  rate  against     cycle  count 

Clock Rate 

CPU Clock Cycles 

CPU Time CPU Clock Cycles Clock Cycle Time 

= 

= ´ 

---

###### CPU  Time  Example 

- Computer  A:  2GHz  clock,  10s  CPU  time 

- Designing  Computer  B 

- Aim  for  6s  CPU  time 

- Can  do  faster  clock,  but  causes  1.2  ×clock  cycles 

- How  fast  must  Computer  B  clock  be? 

 4GHz 6s 

 24 10 6s 

 1.2 20 10 Clock Rate 

 10s 2GHz 20 10 

 Clock Cycles CPU Time Clock Rate 

 6s 

 1.2 Clock Cycles CPU Time 

 Clock Cycles Clock Rate 

 9 9 B 

 9 

 A A A 

 A B 

 B B 

 = 

 ´ = 

 ´ ´ = 

 = ´ = ´ 

 = ´ 

 ´ = = 

---

###### Instruction  Count  and  CPI 

- Instruction  Count  for  a  program 

- Determined  by  program,  ISA  and  compiler 

- Average  cycles  per  instruction 

- Determined  by  CPU  hardware 

- If  different  instructions  have  different  CPI 

- Average  CPI  affected  by  instruction  mix 

Clock Rate 

Instruction Count CPI 

CPU Time Instruction Count CPI Clock Cycle Time 

Clock Cycles Instruction Count Cycles per Instruction 

 ´ = 

= ´ ´ 

= ´ 

---

###### CPI  Example 

- Computer  A:  Cycle  Time  =  250ps,  CPI  =  2.0 

- Computer  B:  Cycle  Time  =  500ps,  CPI  =  1.2 

- Same  ISA 

- Which  is  faster,  and  by  how  much? 

 1.2 I 500ps 

 I 600ps CPU TimeA 

 CPU TimeB 

 I 1.2 500ps I 600ps 

 CPU TimeB Instruction Count CPIB Cycle TimeB 

 I 2.0 250ps I 500ps 

 CPU TimeA Instruction Count CPIA Cycle TimeA 

 = ´ 

 ´ = 

 = ´ ´ = ´ 

 = ´ ´ 

 = ´ ´ = ´ 

 = ´ ´ 

 A  is  faster... 

 ...by  this  much 

---

###### CPI  in  More  Detail 

- If  different  instruction  classes  take  different  numbers  of     cycles 

#### å 

 = 

= ´ 

 n 

 i 1 

Clock Cycles (CPIi Instruction Counti) 

###### n Weighted  average  CPI 

#### å 

 = 

 ÷ ø 

 ö ç è 

 æ = = ´ 

 n 

 i 1 

 i i Instruction Count 

 Instruction Count CPI Instruction Count 

Clock Cycles CPI 

 Relative frequency 

---

###### CPI  Example 

- Alternative  compiled  code  sequences  using     instructions  in  classes  A,  B,  C 

 Class A B C CPI  for  class 1 2 3 IC  in  sequence  1 2 1 2 IC  in  sequence  2 4 1 1 

n Sequence  1:  IC  =  5 

 n Clock  Cycles =  2×1  +  1×2  +  2× 3 =  10 n Avg.  CPI  =  10/5  =  2.0 

 n Sequence  2:  IC  =  6 n Clock  Cycles =  4×1  +  1×2  +  1× 3 =  9 n Avg.  CPI  =  9/6  =  1.5 

---

###### Performance  Summary 

- Performance  depends  on 

- Algorithm:  affects  IC,  possibly  CPI 

- Programming  language:  affects  IC,  CPI 

- Compiler:  affects  IC,  CPI 

- Instruction  set  architecture:  affects  IC,  CPI,  Tc 

The BIG Picture 

Clock cycle 

 Seconds Instruction 

 Clock cycles Program 

 Instructions CPU Time = ´ ´ 

---

#### Structure 

 Figure 1.1 A Top-Down View of a Computer 

 I/O memoryMain 

 CPU 

 COMPUTER 

 SystemBus 

 Registers ALU 

 ControlUnit 

 CPU 

 InternalBus 

 Control UnitRegisters and Decoders 

 CONTROLUNIT SequencingLogic 

 ControlMemory 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

 ª CPU  – controls  the  operation  of the  computer  and  performs  its data  processing  functions ª Main  Memory  – stores  data ª I/O  – moves  data  between  the computer  and  its  external environment ª System  Interconnection  – some  mechanism  that  provides for  communication  among  CPU, main  memory,  and  I/O 

 There  are  four main  structural components of  the  computer: 

©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

## CPU 

- Control  Unit 

- Controls  the  operation  of  the     CPU  and  hence  the  computer 

- Arithmetic  and  Logic  Unit  (ALU) 

- Performs  the  computer’s  data     processing  function 

- Registers 

- Provide  storage  internal  to  the     CPU 

- CPU  Interconnection 

- Some  mechanism  that  provides     for  communication  among  the     control  unit,  ALU,  and  registers 

Major  structural 

components: 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

###### Cache  Memory 

- Multiple  layers  of  memory  between  the 

processor  and  main  memory 

- Is  smaller  and  faster  than  main  memory 

- Used  to  speed  up  memory  access  by  placing 

 in  the  cache  data  from  main  memory  that  is likely  to  be  used  in  the  near  future 

- A  greater  performance  improvement  may  be 

 obtained  by  using  multiple  levels  of  cache, with  level  1  (L1)  closest  to  the  core  and additional  levels  (L2,  L3,  etc.)  progressively farther  from  the  core 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

**Figure 1.2 Simplified View of Major Elements of a Multicore Computer** 

 MOTHERBOARD 

 PROCESSOR CHIP 

 CORE 

 Processorchip 

 Main memory chips 

 I/O chips 

 Core L3 cache 

 Instructionlogic L1 I-cache L2 instructioncache L2 datacache 

 L1 data cache 

 Arithmeticand logic unit (ALU) store logicLoad/ 

 L3 cache 

 Core Core Core 

 Core Core Core Core 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

###### Moore’s  Law 

1965;;  Gordon  Moore  – co-­founder  of  Intel 

 Observed  number  of  transistors  that  could  be put  on  a  single  chip  was  doubling  every  year 

 The  pace  slowed  to  a  doubling  every 18  months  in  the  1970’s  but  has sustained  that  rate  ever  since 

Consequences  of  Moore’s  law: 

 The  cost  of  computer logic  and  memory circuitry  has  fallen  at  a dramatic  rate 

 path  length  is  The  electrical shortened,  increasing operating  speed 

 Computer  becomes smaller  and  is  more use  in  a  variety  convenient  to environmentsof 

 Reduction  in  power  and requirementscooling 

 interchip  Fewer connections 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

 Figure 1.12 Growth in Transistor Count on Integrated Circuits (DRAM memory) 

1947 1 

 First workingtransistor Invention ofintegrated circuitMoore’s lawpromulgated 

 50 55 60 65 70 75 80 85 90 95 2000 05 11 

 10 

 100 

 1,000 

 10.000 

 100,000 

 10 m 

 100 m 

 1 bn 

 10 bn 

 100 bn 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

###### Power  Trends 

- In  CMOS  IC  technology 

 §1.5  The  Power  Wall 

Power =Capacitive load´Voltage^2 ´Frequency 

 × 30 5V  →  1V × 1000 

---

Problems  with  Clock  Speed  and  Login  Density 

- Power 

- Power  density  increases  with  density  of  logic  and  clock  speed 

- Dissipating  heat 

- RC  delay 

- Speed  at  which  electrons  flow  limited  by  resistance  and     capacitance  of  metal  wires  connecting  them 

- Delay  increases  as  the  RC  product  increases 

- As  components  on  the  chip  decrease  in  size,  the  wire     interconnects  become  thinner,  increasing  resistance 

- Also,  the  wires  are  closer  together,  increasing  capacitance 

- Memory  latency 

- Memory  speeds  lag  processor  speeds 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

###### Reducing  Power 

- Suppose  a  new  CPU  has 

- 85%  of  capacitive  load  of  old  CPU 

- 15%  voltage  and  15%  frequency  reduction 

 0.85 0.52 C V F 

 C 0.85 (V 0.85) F 0.85 P 

 P 4 old 

 2 old old 

 old 

 2 old old old 

 new = = ´ ´ 

 ´ ´ ´ ´ ´ = 

###### n The  power  wall 

 n We  can’t  reduce  voltage  further n We  can’t  remove  more  heat 

###### n How  else  can  we  improve  performance? 

---

###### Multiprocessors 

- Multicore  microprocessors 

- More  than  one  processor  per  chip 

- Requires  explicitly  parallel  programming 

- Compare  with  instruction  level  parallelism 

- Hardware  executes  multiple  instructions  at  once 

- Hidden  from  the  programmer 

- Hard  to  do 

- Programming  for  performance 

- Load  balancing 

- Optimizing  communication  and  synchronization 

---

###### Manufacturing  ICs 

- Yield:  proportion  of  working  dies  per  wafer 

 §1.7  Real  Stuff:  The  AMD  Opteron  X4 

---

 Wafer 

 Chip 

 Gate 

 Figure 1.11 Relationship Among Wafer, Chip, and Gate 

 Packaged chip 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

- A thin **wafer** of silicon is divided into     a matrix of small areas, each a few     millimeters square. 

- The identical circuit pattern is     fabricated in each area, and the wafer     is broken up into **chips.** 

- Each chip consists of many gates     and/or memory cells plus a number of     input and output attachment points. 

- This chip is then packaged in housing     that protects it and provides pins for     attachment to devices beyond the chip. 

- A number of these packages can then     be interconnected on a printed circuit     board to produce larger and more     complex circuits. 

## Wafer 

---

###### Benchmark  Principles 

n The same set of programs can be run on different machines and the execution times compared. 

n Benchmarks provide guidance to customers trying to decide which system to buy and can be useful to vendors and designers in determining how to design systems to meet benchmark goals. 

n Desirable  characteristics  of  a  benchmark  program: 

1. It  is  written  in  a  high-­level  language,  making  it  portable  across     different  machines 

2. It  is  representative  of  a  particular  kind  of  programming  domain     or  paradigm,  such  as  systems  programming,  numerical     programming,  or  commercial  programming 

3. It  can  be  measured  easily 

4. It  has  wide  distribution 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

###### Standard  Performance  Evaluation 

###### Corporation  (SPEC) 

n Programs  used  to  measure  performance nSupposedly  typical  of  actual  workload nDevelops  benchmarks  for  CPU,  I/O,  Web,  ... n Performance  measurements  are  widely  used  for comparison  and  research  purposes 

n SPEC  CPU2006 nElapsed  time  to  execute  a  selection  of  programs nNegligible  I/O,  so  focuses  on  CPU  performance nNormalize  relative  to  reference  machine nSummarize  as  geometric  mean  of  performance  ratios nCINT2006  (integer)  and  CFP2006  (floating-­point) 

 n 

 n 

 i 1 

### ÕExecution^ time^ ratioi 

 = 

---

 Standard  Performance  Evaluation  Corporation  SPEC  CPU2006 

- Best  known  SPEC  benchmark  suite 

- Industry  standard  suite  for  processor  intensive  applications 

- Appropriate  for  measuring  performance  for  applications  that     spend  most  of  their  time  doing  computation  rather  than  I/O 

- Consists  of  17  floating  point  programs  written  in  C,  C++,  and     Fortran  and  12  integer  programs  written  in  C  and  C++ 

- Contains  over  3  million  lines  of  code 

- Fifth  generation  of  processor  intensive  suites  from  SPEC 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

## Amdahl’s  Law 

 n Gene  Amdahl n Deals  with  the  potential  speedup  of  a  program  using multiple  processors  compared  to  a  single  processor n Illustrates  the  problems  facing  industry  in  the  development of  multi-­core  machines nSoftware  must  be  adapted  to  a  highly  parallel  execution environment  to  exploit  the  power  of  parallel  processing n Can  be  generalized  to  evaluate  and  design  technical improvement  in  a  computer  system 

 ©  2016  Pearson  Education,  Inc.,  Hoboken,  NJ.  All  rights  reserved. 

---

###### Amdahl’s  Law 

n Improving  an  aspect  of  a  computer  and 

 expecting  a  proportional  improvement  in overall  performance 

 §1.8  Fallacies  and  Pitfalls 

 20 

 80 20 = + n 

 n Can’t  be  done! 

 unaffected 

 affected improved improvement factor T 

 T T = + 

n Example:  multiply  accounts  for  80s/100s 

 n How  much  improvement  in  multiply  performance  to get  5× overall? 

n Corollary:  make  the  common  case  fast 

---

##### Pitfall:  MIPS  as  a  Performance  Metric 

- MIPS:  Millions  of  Instructions  Per  Second 

- Doesn’t  account  for 

- Differences  in  ISAs  between  computers 

- Differences  in  complexity  between  instructions 

 6 6 

 6 

 CPI 10 

 Clock rate 

 10 Clock rate 

 Instruction count CPI 

 Instruction count 

 Execution time 10 

 Instruction count MIPS 

 ´ 

 = ´ 

 ´ 

 = 

 ´ 

 = 

n CPI  varies  between  programs  on  a  given  CPU 

